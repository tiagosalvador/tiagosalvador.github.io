<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>FairCal | Tiago Salvador</title> <meta name="author" content="Tiago Salvador"/> <meta name="description" content="Fairness Calibration for Face Verification"/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="none" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/icon.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://tiagosalvador.github.io/projects/faircal/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="https://tiagosalvador.github.io/"><span class="font-weight-bold">Tiago</span> Salvador</a> <div class="navbar-brand social"> <a href="mailto:%74%69%61%67%6F.%73%61%6C%64%61%6E%68%61%73%61%6C%76%61%64%6F%72@%6D%63%67%69%6C%6C.%63%61" title="email"><i class="fa fa-envelope-square gm-icon"></i></a> <a href="https://scholar.google.com/citations?user=2_dImZEAAAAJ" title="Google Scholar" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar-square gs-icon"></i></a> <a href="https://github.com/tiagosalvador" title="GitHub" target="_blank" rel="noopener noreferrer"><i class="fab fa-github-square gh-icon"></i></a> <a href="https://www.linkedin.com/in/t-salvador" title="LinkedIn" target="_blank" rel="noopener noreferrer"><i class="fab fa-linkedin li-icon"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/news/">news</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">FairCal</h1> <p class="post-description">Fairness Calibration for Face Verification</p> </header> <article> <p>Despite being widely used, face recognition models suffer from bias: the probability of a false positive (incorrect face match) strongly depends on sensitive attributes such as the ethnicity of the face. As a result, these models can disproportionately and negatively impact minority groups, particularly when used by law enforcement.</p> <p>The majority of bias reduction methods have several drawbacks: they use an end-to-end retraining approach, may not be feasible due to privacy issues, and often reduce accuracy. An alternative approach is post-processing methods that build fairer decision classifiers using the features of pre-trained models, thus avoiding the cost of retraining. However, they still have drawbacks: they reduce accuracy (AGENDA, PASS, FTC), or require retuning for different false positive rates (FSN).</p> <p>In this work, we introduce the Fairness Calibration method, <b>FairCal</b>, a post-training approach that simultaneously:</p> <style>ol{list-style:none}ol>li:before{content:attr(seq) " "}</style> <ol> <li seq="(i)">increases model <b>accuracy</b> (improving the state-of-the-art);</li> <li seq="(ii)">produces <b>fairly-calibrated</b> probabilities;</li> <li seq="(iii)">significantly reduces the gap in the <b>false positive rates</b>;</li> <li seq="(iv)">does not require knowledge of the <b>sensitive attribute</b> (group identity such as race, ethnicity, etc.);</li> <li seq="(v)">does not require <b>retraining</b>, training an additional model, or retuning.</li> </ol> <p>We apply it to the task of Face Verification, and obtain state-of-the-art results with all the above advantages. We do so by applying a post-hoc calibration method to pseudo-groups formed by unsupervised clustering.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/rfw_facenet-webface_thr_vs_fpr-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/rfw_facenet-webface_thr_vs_fpr-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/rfw_facenet-webface_thr_vs_fpr-1400.webp"></source> <img src="/assets/img/faircal/rfw_facenet-webface_thr_vs_fpr.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> (Lines closer together is better for fairness) Illustration of improved fairness / reduction in bias, as measured by the FPRs evaluated on intra-ethnicity pairs on the RFW dataset with the FaceNet (Webface) feature model. At a Global FPR of 5% using the baseline method Black people are 15X more likely to false match than white people. Our method reduces this to 1.2X (while SOTA for post-hoc methods is 1.7X). </div> <h3 id="fairness-and-bias-in-face-verification">Fairness and Bias in Face Verification</h3> <p>The Face Verification problem consists in given two images, decide if it is a genuine/imposter pair.</p> <div class="row justify-content-sm-center"> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/images_faces/bart_simpson_1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/images_faces/bart_simpson_1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/images_faces/bart_simpson_1-1400.webp"></source> <img src="/assets/img/faircal/images_faces/bart_simpson_1.jpeg" class="img-fluid rounded z-depth-1" width="100px" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/images_faces/bart_simpson_2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/images_faces/bart_simpson_2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/images_faces/bart_simpson_2-1400.webp"></source> <img src="/assets/img/faircal/images_faces/bart_simpson_2.png" class="img-fluid rounded z-depth-1" width="100px" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-2 mt-3 mt-md-0"> </div> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/images_faces/bart_simpson_1-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/images_faces/bart_simpson_1-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/images_faces/bart_simpson_1-1400.webp"></source> <img src="/assets/img/faircal/images_faces/bart_simpson_1.jpeg" class="img-fluid rounded z-depth-1" width="100px" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-2 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/images_faces/homer_simpson-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/images_faces/homer_simpson-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/images_faces/homer_simpson-1400.webp"></source> <img src="/assets/img/faircal/images_faces/homer_simpson.jpeg" class="img-fluid rounded z-depth-1" width="100px" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row justify-content-sm-center"> <div class="col-sm-2 mt-3 mt-md-0"> Genuine Pair </div> <div class="col-sm-4 mt-3 mt-md-0"> </div> <div class="col-sm-2 mt-3 mt-md-0"> Imposter Pair </div> </div> <p>Chouldechova (2017) showed that maximum two of the following three conditions can be satisfied:</p> <ol> <li seq="1)"> <b>Fairness Calibration</b>, i.e., calibrated fairly for different subgroups:</li> $$ \mathbb{P}_{\boldsymbol{x}_1,\boldsymbol{x}_2 \sim \mathcal{G}_1}(Y=1\mid \widehat{C}=c) = \mathbb{P}_{\boldsymbol{x}_1,\boldsymbol{x}_2 \sim \mathcal{G}_2}(Y=1\mid \widehat{C}=c) = c $$ <li seq="2)"> <b>Predictive Equality</b>, i.e., equal False Positive Rates (FPRs) across different subgroups:</li> $$ \mathbb{P}_{(\boldsymbol{x}_1,\boldsymbol{x}_2) \sim \mathcal{G}_1}(\widehat{Y}=1\mid Y=0) = \mathbb{P}_{(\boldsymbol{x}_1,\boldsymbol{x}_2) \sim\mathcal{G}_2}(\widehat{Y}=1\mid Y=0) $$ <li seq="3)"> <b>Equal Opportunity</b>, i.e., equal False Negative Rates across different subgroups:</li> $$ \mathbb{P}_{(\boldsymbol{x}_1,\boldsymbol{x}_2) \sim \mathcal{G}_1}(\widehat{Y}=0\mid Y=1) = \mathbb{P}_{(\boldsymbol{x}_1,\boldsymbol{x}_2) \sim \mathcal{G}_2}(\widehat{Y}=0\mid Y=1) $$ </ol> <p>In the particular context of policing, <b>predictive equality</b> is considered more important than equal opportunity, as false positive errors (false arrests) risk causing significant harm, especially to members of subgroups already at disproportionate risk for police scrutiny or violence. Hence we choose to omit equal opportunity as our goal and note that no prior method has targeted <b>Fairness Calibration</b>. <b>Predictive equality</b> is measured by comparing the FPR on each subgroup at one global FPR.</p> <h3 id="goals-and-related-work">Goals and Related Work</h3> <p>Work on bias mitigation for deep Face Verification models can be divided into two main camps:</p> <ol> <li seq="(i)">methods that let a model learn less-biased representations during training, and</li> <li seq="(ii)">post-processing approaches that attempt to remove bias <i>after</i> a model is trained.</li> </ol> <p>Our work focuses on (ii) post-hoc methods.</p> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/table-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/table-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/table-1400.webp"></source> <img src="/assets/img/faircal/table.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Comparison of desirable features of the different post-hoc fairness methods for face verification. </div> <h2 id="baseline-approach">Baseline Approach</h2> <p>Given a trained neural network \(f\) that encodes an image \(\boldsymbol{x}\) into an embedding \(\boldsymbol{z} = f(\boldsymbol{x})\), the baseline classifier for the face verification problem is the following.</p> <ol> <li>1) Given an image pair \((\boldsymbol{x}_1,\boldsymbol{x}_2)\): compute the feature embedding pair \((\boldsymbol{z}_1, \boldsymbol{z}_2)\).</li> <li>2) Compute the cosine similarity score \(s(\boldsymbol{x}_1,\boldsymbol{x}_2)=\frac{\boldsymbol{z}_1^T \boldsymbol{z}_2}{\|\boldsymbol{z}_1\| \|\boldsymbol{z}_2\|}\).</li> <li>3) Given a predefined threshold \(s_{\rm{thr}}: s(\boldsymbol{x}_1,\boldsymbol{x}_2) &gt; s_{\rm{thr}} \implies\) genuine pair!</li> </ol> <h3 id="faircal">FairCal</h3> <p>We build our proposed method <b>FairCal</b> based on two main ideas:</p> <ol> <li>1) Use the feature vector to define population subgroups;</li> <li>2) Use post-hoc calibration methods that convert cosine similarity scores into probabilities of genuine (or imposter) pair.</li> </ol> <h5 id="calibration-stage"><u>Calibration stage</u></h5> <p>Let \(\mathcal{Z}^{\rm{cal}}\) denote the feature embeddings of a set of face images.</p> <ol> <li> <p>1) Apply \(K\)-means algorithm to \(\mathcal{Z}^{\rm{cal}}\), partitioning the embedding space into \(K\) clusters \(\mathcal{Z}_1,\ldots,\mathcal{Z}_K\)</p> </li> <li> <p>2) Form the \(K\) calibration sets of cosine similarity scores:</p> </li> </ol> \[S^{\rm{cal}}_k = \left\{ s(\boldsymbol{x}_1,\boldsymbol{x}_2): f(\boldsymbol{x}_1) \in \mathcal{Z}_k \text{ or } f(\boldsymbol{x}_2) \in \mathcal{Z}_k \right\}, \quad k = 1, \dots, K\] <ol> <li>3) For \(k=1,\ldots,K\) estimate the calibration map \(\mu_k\) that calibrates the scores:</li> </ol> \[\mu_k (s(\boldsymbol{x}_1,\boldsymbol{x}_2)) = \mathbb{P}[Y=1\mid S=s, f(\boldsymbol{x}_1) \in \mathcal{Z}_k \text{ or } f(\boldsymbol{x}_2) \in \mathcal{Z}_k]\] <p>For <b>FairCal</b> we chose Beta Calibration (Kull et al, 2017) as the post-hoc calibration method but experiments show similar performance with other calibration methods.</p> <h5 id="test-stage"><u>Test stage</u></h5> <ol> <li>1) Given an image pair (\(\boldsymbol{x}_1\), \(\boldsymbol{x}_2\)), compute (\(z_1\), \(z_2\)), and the cluster of each image feature: \(k_1\) and \(k_2\)</li> <li>2) The model’s confidence \(c\) in it being a genuine pair is:</li> </ol> \[c(\boldsymbol{x}_1,\boldsymbol{x}_2) = \theta\ \mu_{k_1}(s(\boldsymbol{x}_1,\boldsymbol{x}_2))\ + (1-\theta)\ \mu_{k_2}(s(\boldsymbol{x}_1,\boldsymbol{x}_2))\] <p>where \(\theta = \frac{\|S^{\rm{cal}}_{k_1}\|}{\|S^{\rm{cal}}_{k_1}\|+\|S^{\rm{cal}}_{k_2}\|}\) is the relative population fraction of the two clusters.</p> <ol> <li>3) Given a predefined threshold \(c_{\rm{thr}}: c(\boldsymbol{x}_1,\boldsymbol{x}_2) &gt; c_{\rm{thr}} \implies\) genuine pair!</li> </ol> <div class="row justify-content-sm-center"> <div class="col-sm-12 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/diagram_faircal-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/diagram_faircal-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/diagram_faircal-1400.webp"></source> <img src="/assets/img/faircal/diagram_faircal.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Illustrative diagram of our <b>FairCal</b> method. Highlighted in red are the components that distinguish it from the baseline approach. </div> <h3 id="results">Results</h3> <p>Our results show that among post hoc calibration methods,</p> <ol> <li>1) <b>FairCal</b> has the <u>best Fairness Calibration</u>.</li> <li>2) <b>FairCal</b> has the <u>best Predictive Equality</u>, i.e., equal FPRs,</li> <li>3) <b>FairCal</b> has the <u>best global accuracy</u>,</li> <li>4) <b>FairCal</b> <u>does not require the sensitive attribute</u> and outperforms methods that use this knowledge,</li> <li>5) <b>FairCal</b> <u>does not require retraining</u> of the classifier, or any additional training.</li> </ol> <h3 id="unsupervised-clusters">Unsupervised Clusters</h3> <p>In order to not rely on the sensitive attribute like the Oracle method, our <b>FairCal</b> method uses unsupervised clusters computed with the K-means algorithm based on the feature embeddings of the images. We found them to have semantic meaning.</p> <div class="row justify-content-sm-center"> <div class="col-sm-5 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_38-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_38-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_38-1400.webp"></source> <img src="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_38.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-5 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_4-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_4-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_4-1400.webp"></source> <img src="/assets/img/faircal/cluster_visualization/facenet_fold5_cluster_4.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Examples of clusters obtained with the K-means algorithm (K=100) on the RFW dataset based on the feature embeddings computed with the FaceNet model. The left cluster is predominantly composed of Caucasian Blonde Women, while the right cluster is composed of Indian Men with Moustaches. </div> <h3 id="citation">Citation</h3> <p>You can see the full paper <a href="https://openreview.net/pdf?id=nRj0NcmSuxb" target="_blank" rel="noopener noreferrer">here</a>. Please cite as</p> <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{salvador2022faircal,
    title={FairCal: Fairness Calibration for Face Verification},
    author={Tiago Salvador and Stephanie Cairns and Vikram Voleti and Noah Marshall and Adam M Oberman},
    booktitle={International Conference on Learning Representations},
    year={2022},
    url={https://openreview.net/forum?id=nRj0NcmSuxb}
}
</code></pre></div></div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2022 Tiago Salvador. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Last updated: November 23, 2022. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>